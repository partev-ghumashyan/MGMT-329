{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting requests\n",
      "  Downloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Collecting beautifulsoup4\n",
      "  Downloading beautifulsoup4-4.12.3-py3-none-any.whl (147 kB)\n",
      "Collecting pandas\n",
      "  Downloading pandas-2.2.3-cp39-cp39-macosx_11_0_arm64.whl (11.3 MB)\n",
      "Collecting charset-normalizer<4,>=2\n",
      "  Downloading charset_normalizer-3.4.0-cp39-cp39-macosx_11_0_arm64.whl (120 kB)\n",
      "Collecting certifi>=2017.4.17\n",
      "  Downloading certifi-2024.8.30-py3-none-any.whl (167 kB)\n",
      "Collecting idna<4,>=2.5\n",
      "  Downloading idna-3.10-py3-none-any.whl (70 kB)\n",
      "Collecting urllib3<3,>=1.21.1\n",
      "  Downloading urllib3-2.2.3-py3-none-any.whl (126 kB)\n",
      "Collecting soupsieve>1.2\n",
      "  Downloading soupsieve-2.6-py3-none-any.whl (36 kB)\n",
      "Collecting numpy>=1.22.4\n",
      "  Downloading numpy-2.0.2-cp39-cp39-macosx_11_0_arm64.whl (13.7 MB)\n",
      "Collecting pytz>=2020.1\n",
      "  Downloading pytz-2024.2-py2.py3-none-any.whl (508 kB)\n",
      "Collecting tzdata>=2022.7\n",
      "  Downloading tzdata-2024.2-py2.py3-none-any.whl (346 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/partevghumashyan/Library/Python/3.9/lib/python/site-packages (from pandas->-r requirements.txt (line 3)) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas->-r requirements.txt (line 3)) (1.15.0)\n",
      "Installing collected packages: urllib3, tzdata, soupsieve, pytz, numpy, idna, charset-normalizer, certifi, requests, pandas, beautifulsoup4\n",
      "Successfully installed beautifulsoup4-4.12.3 certifi-2024.8.30 charset-normalizer-3.4.0 idna-3.10 numpy-2.0.2 pandas-2.2.3 pytz-2024.2 requests-2.32.3 soupsieve-2.6 tzdata-2024.2 urllib3-2.2.3\n",
      "All packages installed successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.2.4; however, version 24.2 is available.\n",
      "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "# Automatically install dependencies from requirements.txt\n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "# Define a function to install packages\n",
    "def install_requirements():\n",
    "    try:\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-r\", \"requirements.txt\"])\n",
    "        print(\"All packages installed successfully.\")\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(\"An error occurred while installing packages:\", e)\n",
    "\n",
    "# Run the function\n",
    "install_requirements()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# Lists to hold quote information\n",
    "quotes_list = []\n",
    "authors_list = []\n",
    "tags_list = []\n",
    "born_list = []\n",
    "desc_list = []\n",
    "\n",
    "# Base URL for quotes and author pages\n",
    "base_url = \"https://quotes.toscrape.com/\"\n",
    "page_url = \"https://quotes.toscrape.com/page/{}/\"\n",
    "\n",
    "# Loop over all pages\n",
    "page_number = 1\n",
    "while True:\n",
    "    response = requests.get(page_url.format(page_number))\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    \n",
    "    # Find all quotes on the current page\n",
    "    quotes = soup.find_all(\"div\", class_=\"quote\")\n",
    "    if not quotes:\n",
    "        print(\"No more quotes found, stopping.\")\n",
    "        break  # Exit the loop if no quotes found (end of pagination)\n",
    "\n",
    "    for quote in quotes:\n",
    "        # Extract quote text\n",
    "        text = quote.find(\"span\", class_=\"text\").get_text(strip=True)\n",
    "        # Extract author\n",
    "        author = quote.find(\"small\", class_=\"author\").get_text(strip=True)\n",
    "        # Extract tags\n",
    "        tags = [tag.get_text(strip=True) for tag in quote.find_all(\"a\", class_=\"tag\")]\n",
    "\n",
    "        # Access the author's detail page for additional info\n",
    "        author_url = base_url + quote.find(\"a\")[\"href\"]\n",
    "        author_response = requests.get(author_url)\n",
    "        author_soup = BeautifulSoup(author_response.text, \"html.parser\")\n",
    "\n",
    "        # Extract author's birth date and description\n",
    "        born_date = author_soup.find(\"span\", class_=\"author-born-date\").get_text(strip=True)\n",
    "        born_location = author_soup.find(\"span\", class_=\"author-born-location\").get_text(strip=True)\n",
    "        born = f\"{born_date}, {born_location}\"\n",
    "        description = author_soup.find(\"div\", class_=\"author-description\").get_text(strip=True)\n",
    "\n",
    "        # Append data to lists\n",
    "        quotes_list.append(text)\n",
    "        authors_list.append(author)\n",
    "        tags_list.append(\", \".join(tags))\n",
    "        born_list.append(born)\n",
    "        desc_list.append(description)\n",
    "\n",
    "        # Be respectful with delays for author page requests\n",
    "        time.sleep(1)\n",
    "\n",
    "    # Move to the next page\n",
    "    page_number += 1\n",
    "\n",
    "# Create a DataFrame from collected data\n",
    "data = {\n",
    "    \"Quote\": quotes_list,\n",
    "    \"Author\": authors_list,\n",
    "    \"Tags\": tags_list,\n",
    "    \"Born\": born_list,\n",
    "    \"Description\": desc_list\n",
    "}\n",
    "df = pd.DataFrame(data)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
